{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data & Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this if you need to install kaggle API\n",
    "# !pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_name = input('Input your Kaggle API Username:')\n",
    "kaggle_key = input('Input your Kaggle API key:')\n",
    "\n",
    "!set KAGGLE_USERNAME=$kaggle_name\n",
    "!set KAGGLE_KEY=$kaggle_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading titanic.zip to D:\\kyalan\\Documents\\GitHub\\kaggle\\02_Titanic\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/34.1k [00:00<?, ?B/s]\n",
      "100%|██████████| 34.1k/34.1k [00:00<00:00, 36.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# try to download datasets\n",
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\02-titanic.ipynb\n",
      ".\\titanic.zip\n",
      ".\\.ipynb_checkpoints\\02-titanic-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip to extract data\n",
    "import zipfile\n",
    "with zipfile.ZipFile('titanic.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('titanic/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source 1: import from Kaggle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_1 = pd.read_csv(r'.\\titanic\\input\\train.csv')\n",
    "df_raw_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source 2: import from tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_fromtfds():\n",
    "    \n",
    "    import tensorflow_datasets as tfds\n",
    "    ds = tfds.load('titanic', split='train', as_supervised=True)\n",
    "    \n",
    "    # Convert from tfds to df\n",
    "    df_raw = pd.DataFrame()\n",
    "    for ds_row in list(ds):\n",
    "        row = ds_row[0]\n",
    "        row['Survived'] = ds_row[1]\n",
    "        df_raw = df_raw.append(row, ignore_index=True)\n",
    "\n",
    "    # Convert from tensor object to numpy\n",
    "    for col in df_raw:\n",
    "        df_raw[col] = df_raw[col].apply(lambda x: x.numpy())\n",
    "        if col in ['cabin', 'home.dest', 'name', 'ticket', 'boat']:\n",
    "            df_raw[col] = df_raw[col].apply(lambda x: x.decode())\n",
    "\n",
    "    df_raw.columns = df_raw.columns.str.capitalize()\n",
    "    df_raw.Pclass += 1\n",
    "    df_raw.Sex.replace([0,1], ['male', 'female'], inplace=True)\n",
    "    df_raw.Cabin.replace('Unknown', np.nan, inplace=True)\n",
    "    df_raw.Age.replace(-1, np.nan, inplace=True)\n",
    "    df_raw.Fare.replace(-1, np.nan, inplace=True)\n",
    "    df_raw.Embarked.replace([0,1,2,3], ['C', 'Q', 'S', None], inplace=True)\n",
    "    df_raw.rename(columns={'Sibsp':'SibSp'}, inplace=True)\n",
    "\n",
    "    df_raw.drop(['Boat', 'Home.dest', 'Body'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Ticket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>McCrie, Mr. James Matthew</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>233478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Gustafsson, Mr. Anders Vilhelm</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>3101276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Reynaldo, Ms. Encarnacion</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>230434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>Davies, Mr. Charles Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>S.O.C. 14879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>Gheorgheff, Mr. Stanio</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>349254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age Cabin Embarked     Fare                            Name  \\\n",
       "0         0  30.0   NaN        S  13.0000       McCrie, Mr. James Matthew   \n",
       "1         0  37.0   NaN        S   7.9250  Gustafsson, Mr. Anders Vilhelm   \n",
       "2         1  28.0   NaN        S  13.0000       Reynaldo, Ms. Encarnacion   \n",
       "3         0  18.0   NaN        S  73.5000       Davies, Mr. Charles Henry   \n",
       "4         0   NaN   NaN        C   7.8958          Gheorgheff, Mr. Stanio   \n",
       "\n",
       "   Parch  Pclass     Sex  SibSp        Ticket  \n",
       "0      0       2    male      0        233478  \n",
       "1      0       3    male      2       3101276  \n",
       "2      0       2  female      0        230434  \n",
       "3      0       2    male      0  S.O.C. 14879  \n",
       "4      0       3    male      0        349254  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw_2 = getdata_fromtfds()\n",
    "df_raw_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          1.0         0       3   \n",
       "1          2.0         1       1   \n",
       "2          3.0         1       3   \n",
       "3          4.0         1       1   \n",
       "4          5.0         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.concat([df_raw_1, df_raw_2])\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2200 entries, 0 to 1308\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    float64\n",
      " 1   Survived     2200 non-null   int64  \n",
      " 2   Pclass       2200 non-null   int64  \n",
      " 3   Name         2200 non-null   object \n",
      " 4   Sex          2200 non-null   object \n",
      " 5   Age          1760 non-null   float64\n",
      " 6   SibSp        2200 non-null   int64  \n",
      " 7   Parch        2200 non-null   int64  \n",
      " 8   Ticket       2200 non-null   object \n",
      " 9   Fare         2199 non-null   float64\n",
      " 10  Cabin        499 non-null    object \n",
      " 11  Embarked     2196 non-null   object \n",
      "dtypes: float64(3), int64(4), object(5)\n",
      "memory usage: 223.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_0(df_raw):\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    if 'PassengerId' in df_raw:\n",
    "        df.drop('PassengerId', axis=1, inplace=True)\n",
    "    \n",
    "    df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "    df['FamilyCat'] = np.where(df['FamilySize']==1, 'Singleton', None)\n",
    "    df['FamilyCat'] = np.where((2 <= df['FamilySize']) & (df['FamilySize'] <= 4), 'SmallFamily', df['FamilyCat'])\n",
    "    df['FamilyCat'] = np.where(5 <= df['FamilySize'], 'LargeFamily', df['FamilyCat'])\n",
    "    \n",
    "    df['Embarked'].fillna('S', inplace=True)\n",
    "    \n",
    "    df['Cabin'].fillna('T', inplace=True)\n",
    "    \n",
    "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "    \n",
    "    df['Cabin N'] = df.Cabin.str.count(' ') + 1.0\n",
    "    df['Cabin Deck'] = df.Cabin.str.slice(0,1)\n",
    "    df['Cabin Room'] = df.Cabin.str.slice(1,5).str.extract(\"([0-9]+)\", expand=False).astype(\"float\")\n",
    "    \n",
    "    df[\"Title\"] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'].replace('Mlle', 'Miss', inplace=True)\n",
    "    df['Title'].replace('Ms', 'Miss', inplace=True)\n",
    "    df['Title'].replace('Mme', 'Mrs', inplace=True)    \n",
    "    df['Title'].replace([\"Capt\",\"Don\",\"Major\",\"Dr\",\"Rev\", \"Col\"], 'Officer', inplace=True)\n",
    "    df['Title'].replace([\"Jonkheer\",\"Don\", \"Dona\", \"Sir\", \"Countess\", \"Lady\"], 'Royalty', inplace=True)\n",
    "    \n",
    "    grouped_median_train = df.groupby(['Sex', 'Pclass', 'Title']).median().reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "    def fill_age(row):\n",
    "        condition = (\n",
    "            (grouped_median_train['Sex']==row['Sex']) \\\n",
    "            & (grouped_median_train['Title']==row['Title']) \\\n",
    "            & (grouped_median_train['Pclass']==row['Pclass'])\n",
    "        )\n",
    "        if np.isnan(grouped_median_train[condition]['Age'].values[0]):\n",
    "            condition = (\n",
    "                (grouped_median_train['Sex']==row['Sex']) \\\n",
    "                & (grouped_median_train['Pclass']==row['Pclass'])\n",
    "            )\n",
    "        return grouped_median_train[condition]['Age'].values[0]\n",
    "    df['Age'] = df.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis = 1)\n",
    "    \n",
    "    df[\"Surname\"] = df.Name.str.split(',').str.get(0)\n",
    "    df['SurnameFreq']=df.groupby('Surname')['Surname'].transform('count')\n",
    "    df['TicketFreq']=df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    df['CustomizedFare']=df.Fare/(df.TicketFreq*df.Pclass)\n",
    "    \n",
    "    df.drop(['Name', 'Cabin', 'Surname', 'Ticket'], axis=1, inplace=True)\n",
    "    df = df[df.columns.sort_values()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor_0(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2200 entries, 0 to 1308\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             2200 non-null   float64\n",
      " 1   Cabin Deck      2200 non-null   object \n",
      " 2   Cabin N         2200 non-null   float64\n",
      " 3   Cabin Room      489 non-null    float64\n",
      " 4   CustomizedFare  2200 non-null   float64\n",
      " 5   Embarked        2200 non-null   object \n",
      " 6   FamilyCat       2200 non-null   object \n",
      " 7   FamilySize      2200 non-null   int64  \n",
      " 8   Fare            2200 non-null   float64\n",
      " 9   Parch           2200 non-null   int64  \n",
      " 10  Pclass          2200 non-null   int64  \n",
      " 11  Sex             2200 non-null   object \n",
      " 12  SibSp           2200 non-null   int64  \n",
      " 13  SurnameFreq     2200 non-null   int64  \n",
      " 14  Survived        2200 non-null   int64  \n",
      " 15  TicketFreq      2200 non-null   int64  \n",
      " 16  Title           2200 non-null   object \n",
      "dtypes: float64(5), int64(7), object(5)\n",
      "memory usage: 309.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is split. Train X, y shapes = (1980, 16), (1980,). Dev X, y shapes = (220, 16), (220,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_X = df.drop('Survived', axis=True)\n",
    "df_y = df['Survived']\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(df_X, df_y, test_size=0.1, random_state=9527, stratify=df_y)\n",
    "print('df is split. Train X, y shapes = {}, {}. Dev X, y shapes = {}, {}'.format(X_train.shape, y_train.shape, X_dev.shape, y_dev.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn pipeline building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass'\n",
    "#                     , 'Cabin N', 'Cabin Room', 'SurnameFreq', 'TicketFreq', 'CustomizedFare'\n",
    "                    , 'FamilySize']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "    , ('logtransformer', FunctionTransformer(np.log1p))\n",
    "    , ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Embarked', 'Sex', 'Cabin Deck', 'Title', 'FamilyCat']\n",
    "# categorical_features = ['Sex', 'Pclass', 'Cabin Deck', 'Title']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is transformed by sklearn preprocessor. Train X, y shapes = (1980, 28), (1980,). Dev X, y shapes = (220, 28), (220,)\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocessor_1.fit_transform(X_train)\n",
    "X_dev = preprocessor_1.transform(X_dev)\n",
    "\n",
    "print('X is transformed by sklearn preprocessor. Train X, y shapes = {}, {}. Dev X, y shapes = {}, {}'.format(X_train.shape, y_train.shape, X_dev.shape, y_dev.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models list imported. with length = 11\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param = {'objective':'binary:logistic', 'n_estimators': 20, 'n_jobs': 4\n",
    "         , 'max_depth': 50, 'learning_rate': 0.3, 'reg_lambda': 0.01\n",
    "         , 'gamma': 2, 'max_delta_step': 1, 'min_child_weight': 1\n",
    "         , 'colsample_bytree': 0.65, 'subsample': 0.9, 'base_score': 0.5\n",
    "        }\n",
    "models.append(XGBClassifier(**param))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "param = {'n_estimators': 180, 'min_samples_split': 3\n",
    "#          , 'min_samples_leaf': 4, 'max_depth': 32, 'bootstrap': True\n",
    "         , 'max_features': 0.5\n",
    "        }\n",
    "models.append(RandomForestClassifier(**param))\n",
    "models.append(AdaBoostClassifier())\n",
    "models.append(GradientBoostingClassifier())\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models.append(DecisionTreeClassifier())\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models.append(KNeighborsClassifier())\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "models.append(SVC(probability=True))\n",
    " \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models.append(GaussianNB())\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "models.append(QuadraticDiscriminantAnalysis())\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models.append(LogisticRegression())\n",
    "\n",
    "print('Models list imported. with length = {}'.format(len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGBClassifier...\n",
      "[23:50:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Running RandomForestClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\kyalan\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AdaBoostClassifier...\n",
      "Running GradientBoostingClassifier...\n",
      "Running DecisionTreeClassifier...\n",
      "Running KNeighborsClassifier...\n",
      "Running SVC...\n",
      "Running GaussianNB...\n",
      "Running LinearDiscriminantAnalysis...\n",
      "Running QuadraticDiscriminantAnalysis...\n",
      "Running LogisticRegression...\n",
      "     acc_dev  acc_train                           name\n",
      "0   0.922727   0.931818                  XGBClassifier\n",
      "1   0.950000   0.973232         RandomForestClassifier\n",
      "2   0.863636   0.826263             AdaBoostClassifier\n",
      "3   0.900000   0.874747     GradientBoostingClassifier\n",
      "4   0.950000   0.974242         DecisionTreeClassifier\n",
      "5   0.881818   0.867172           KNeighborsClassifier\n",
      "6   0.859091   0.828283                            SVC\n",
      "7   0.840909   0.794444                     GaussianNB\n",
      "8   0.859091   0.817677     LinearDiscriminantAnalysis\n",
      "9   0.677273   0.680808  QuadraticDiscriminantAnalysis\n",
      "10  0.854545   0.822222             LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\kyalan\\anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "df_acc = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    print('Running {}...'.format(model_name))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, y_train_pred)\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    acc_dev = accuracy_score(y_dev, y_dev_pred)\n",
    "    \n",
    "    df_acc = df_acc.append({'name': model_name, 'acc_dev': acc_dev, 'acc_train': acc_train}, ignore_index=True)\n",
    "        \n",
    "print(df_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "#     param = {'objective':'binary:logistic', 'n_estimators': 20, 'n_jobs': 4\n",
    "#              , 'max_depth': 50, 'learning_rate': 0.3, 'reg_lambda': 0.01\n",
    "#              , 'gamma': 2, 'max_delta_step': 1, 'min_child_weight': 1\n",
    "#              , 'colsample_bytree': 0.65, 'subsample': 0.9, 'base_score': 0.5\n",
    "#             }\n",
    "#     model = XGBClassifier(**param)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    param = {'n_estimators': 180, 'min_samples_split': 3\n",
    "    #          , 'min_samples_leaf': 4, 'max_depth': 32, 'bootstrap': True\n",
    "             , 'max_features': 0.5\n",
    "            }  \n",
    "    model = RandomForestClassifier(**param)\n",
    "    \n",
    "#     from sklearn.tree import DecisionTreeClassifier\n",
    "#     model = DecisionTreeClassifier()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = getModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the best parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid = {'n_estimators':[20]\n",
    "#         , 'max_depth':[50]\n",
    "#         , 'learning_rate':[0.3]\n",
    "#         , 'reg_lambda':[0.01]\n",
    "#         , 'gamma':[2]\n",
    "#         , 'max_delta_step':[0,1,2]\n",
    "#         , 'min_child_weight':[1,2,3]\n",
    "#         , 'colsample_bytree':[0.55,0.65]\n",
    "#         , 'subsample':[1,0.9,0.8]\n",
    "#         , 'base_score':[0.5]        \n",
    "#        }\n",
    "\n",
    "# search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', n_jobs=4, refit=True)\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# print(search.best_params_)\n",
    "# print(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=0.5, min_samples_split=3, n_estimators=180)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train\n",
    "#           , eval_set=[(X_train, y_train), (X_dev, y_dev)]\n",
    "#           , eval_metric=['error', 'logloss'], verbose=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train data: 0.9732323232323232\n",
      "Accuracy of dev data: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('Accuracy of train data:', accuracy_score(y_train, y_train_pred))\n",
    "y_dev_pred = model.predict(X_dev)\n",
    "print('Accuracy of dev data:', accuracy_score(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_raw = pd.read_csv(r'.\\titanic\\input\\test.csv')\n",
    "df_submit = preprocessor_0(df_submit_raw)\n",
    "X_submit = preprocessor_1.transform(df_submit)\n",
    "\n",
    "df_submit_final = pd.DataFrame(df_submit_raw['PassengerId'])\n",
    "df_submit_final['Survived'] = pd.Series(model.predict(X_submit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_final.to_csv(r'.\\submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Titanic - Machine Learning from Disaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/3.18k [00:00<?, ?B/s]\n",
      "100%|██████████| 3.18k/3.18k [00:05<00:00, 583B/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit titanic -f .\\submission.csv -m \"Adding in tfds data for training\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Score: 0.91148 ; Rank 637 / 35554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the raw data and Closing file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "shutil.rmtree('titanic')\n",
    "os.remove('titanic.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\02-titanic.ipynb\n",
      ".\\submission.csv\n",
      ".\\.ipynb_checkpoints\\02-titanic-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
