{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/titanic/gender_submission.csv\n",
      "/kaggle/input/titanic/test.csv\n",
      "/kaggle/input/titanic/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1: import from tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata_fromtfds():\n",
    "    \n",
    "    import tensorflow_datasets as tfds\n",
    "    ds = tfds.load('titanic', split='train', as_supervised=True)\n",
    "    \n",
    "    # Convert from tfds to df\n",
    "    df_raw = pd.DataFrame()\n",
    "    for ds_row in list(ds):\n",
    "        row = ds_row[0]\n",
    "        row['Survived'] = ds_row[1]\n",
    "        df_raw = df_raw.append(row, ignore_index=True)\n",
    "\n",
    "    # Convert from tensor object to numpy\n",
    "    for col in df_raw:\n",
    "        df_raw[col] = df_raw[col].apply(lambda x: x.numpy())\n",
    "        if col in ['cabin', 'home.dest', 'name', 'ticket', 'boat']:\n",
    "            df_raw[col] = df_raw[col].apply(lambda x: x.decode())\n",
    "\n",
    "    df_raw.columns = df_raw.columns.str.capitalize()\n",
    "    df_raw.Pclass += 1\n",
    "    df_raw.Sex.replace([0,1], ['male', 'female'], inplace=True)\n",
    "    df_raw.Cabin.replace('Unknown', np.nan, inplace=True)\n",
    "    df_raw.Age.replace(-1, np.nan, inplace=True)\n",
    "    df_raw.Fare.replace(-1, np.nan, inplace=True)\n",
    "    df_raw.Embarked.replace([0,1,2,3], ['C', 'Q', 'S', None], inplace=True)\n",
    "    df_raw.rename(columns={'Sibsp':'SibSp'}, inplace=True)\n",
    "\n",
    "    df_raw.drop(['Boat', 'Home.dest', 'Body'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw = getdata_fromtfds()\n",
    "df_raw = pd.read_csv('/kaggle/input/titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor_0(df_raw):\n",
    "    \n",
    "    df = df_raw.copy()\n",
    "    \n",
    "    if 'PassengerId' in df_raw:\n",
    "        df.drop('PassengerId', axis=1, inplace=True)\n",
    "    \n",
    "    df['FamilySize'] = df['Parch'] + df['SibSp'] + 1\n",
    "    df['FamilyCat'] = np.where(df['FamilySize']==1, 'Singleton', None)\n",
    "    df['FamilyCat'] = np.where((2 <= df['FamilySize']) & (df['FamilySize'] <= 4), 'SmallFamily', df['FamilyCat'])\n",
    "    df['FamilyCat'] = np.where(5 <= df['FamilySize'], 'LargeFamily', df['FamilyCat'])\n",
    "    \n",
    "    df['Embarked'].fillna('S', inplace=True)\n",
    "    \n",
    "    df['Cabin'].fillna('T', inplace=True)\n",
    "    \n",
    "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "    \n",
    "    df['Cabin N'] = df.Cabin.str.count(' ') + 1.0\n",
    "    df['Cabin Deck'] = df.Cabin.str.slice(0,1)\n",
    "    df['Cabin Room'] = df.Cabin.str.slice(1,5).str.extract(\"([0-9]+)\", expand=False).astype(\"float\")\n",
    "    \n",
    "    df[\"Title\"] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'].replace('Mlle', 'Miss', inplace=True)\n",
    "    df['Title'].replace('Ms', 'Miss', inplace=True)\n",
    "    df['Title'].replace('Mme', 'Mrs', inplace=True)    \n",
    "    df['Title'].replace([\"Capt\",\"Don\",\"Major\",\"Dr\",\"Rev\", \"Col\"], 'Officer', inplace=True)\n",
    "    df['Title'].replace([\"Jonkheer\",\"Don\", \"Dona\", \"Sir\", \"Countess\", \"Lady\"], 'Royalty', inplace=True)\n",
    "    \n",
    "    grouped_median_train = df.groupby(['Sex', 'Pclass', 'Title']).median().reset_index()[['Sex', 'Pclass', 'Title', 'Age']]\n",
    "    def fill_age(row):\n",
    "        condition = (\n",
    "            (grouped_median_train['Sex']==row['Sex']) \\\n",
    "            & (grouped_median_train['Title']==row['Title']) \\\n",
    "            & (grouped_median_train['Pclass']==row['Pclass'])\n",
    "        )\n",
    "        if np.isnan(grouped_median_train[condition]['Age'].values[0]):\n",
    "            condition = (\n",
    "                (grouped_median_train['Sex']==row['Sex']) \\\n",
    "                & (grouped_median_train['Pclass']==row['Pclass'])\n",
    "            )\n",
    "        return grouped_median_train[condition]['Age'].values[0]\n",
    "    df['Age'] = df.apply(lambda row: fill_age(row) if np.isnan(row['Age']) else row['Age'], axis = 1)\n",
    "    \n",
    "    df[\"Surname\"] = df.Name.str.split(',').str.get(0)\n",
    "    df['SurnameFreq']=df.groupby('Surname')['Surname'].transform('count')\n",
    "    df['TicketFreq']=df.groupby('Ticket')['Ticket'].transform('count')\n",
    "    df['CustomizedFare']=df.Fare/(df.TicketFreq*df.Pclass)\n",
    "    \n",
    "    df.drop(['Name', 'Cabin', 'Surname', 'Ticket'], axis=1, inplace=True)\n",
    "    df = df[df.columns.sort_values()]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor_0(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             891 non-null    float64\n",
      " 1   Cabin Deck      891 non-null    object \n",
      " 2   Cabin N         891 non-null    float64\n",
      " 3   Cabin Room      200 non-null    float64\n",
      " 4   CustomizedFare  891 non-null    float64\n",
      " 5   Embarked        891 non-null    object \n",
      " 6   FamilyCat       891 non-null    object \n",
      " 7   FamilySize      891 non-null    int64  \n",
      " 8   Fare            891 non-null    float64\n",
      " 9   Parch           891 non-null    int64  \n",
      " 10  Pclass          891 non-null    int64  \n",
      " 11  Sex             891 non-null    object \n",
      " 12  SibSp           891 non-null    int64  \n",
      " 13  SurnameFreq     891 non-null    int64  \n",
      " 14  Survived        891 non-null    int64  \n",
      " 15  TicketFreq      891 non-null    int64  \n",
      " 16  Title           891 non-null    object \n",
      "dtypes: float64(5), int64(7), object(5)\n",
      "memory usage: 118.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df is split. Train X, y shapes = (801, 16), (801,). Dev X, y shapes = (90, 16), (90,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_X = df.drop('Survived', axis=True)\n",
    "df_y = df['Survived']\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(df_X, df_y, test_size=0.1, random_state=9527, stratify=df_y)\n",
    "print('df is split. Train X, y shapes = {}, {}. Dev X, y shapes = {}, {}'.format(X_train.shape, y_train.shape, X_dev.shape, y_dev.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn pipeline building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_features = ['Age', 'Fare', 'SibSp', 'Parch', 'Pclass'\n",
    "#                     , 'Cabin N', 'Cabin Room', 'SurnameFreq', 'TicketFreq', 'CustomizedFare'\n",
    "                    , 'FamilySize']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "    , ('logtransformer', FunctionTransformer(np.log1p))\n",
    "    , ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Embarked', 'Sex', 'Cabin Deck', 'Title', 'FamilyCat']\n",
    "# categorical_features = ['Sex', 'Pclass', 'Cabin Deck', 'Title']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_1 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X is transformed by sklearn preprocessor. Train X, y shapes = (801, 28), (801,). Dev X, y shapes = (90, 28), (90,)\n"
     ]
    }
   ],
   "source": [
    "X_train = preprocessor_1.fit_transform(X_train)\n",
    "X_dev = preprocessor_1.transform(X_dev)\n",
    "\n",
    "print('X is transformed by sklearn preprocessor. Train X, y shapes = {}, {}. Dev X, y shapes = {}, {}'.format(X_train.shape, y_train.shape, X_dev.shape, y_dev.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models list imported. with length = 11\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "param = {'objective':'binary:logistic', 'n_estimators': 20, 'n_jobs': 4\n",
    "         , 'max_depth': 50, 'learning_rate': 0.3, 'reg_lambda': 0.01\n",
    "         , 'gamma': 2, 'max_delta_step': 1, 'min_child_weight': 1\n",
    "         , 'colsample_bytree': 0.65, 'subsample': 0.9, 'base_score': 0.5\n",
    "        }\n",
    "models.append(XGBClassifier(**param))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "param = {'n_estimators': 180, 'min_samples_split': 3\n",
    "#          , 'min_samples_leaf': 4, 'max_depth': 32, 'bootstrap': True\n",
    "         , 'max_features': 0.5\n",
    "        }\n",
    "models.append(RandomForestClassifier(**param))\n",
    "models.append(AdaBoostClassifier())\n",
    "models.append(GradientBoostingClassifier())\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models.append(DecisionTreeClassifier())\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models.append(KNeighborsClassifier())\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "models.append(SVC(probability=True))\n",
    " \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models.append(GaussianNB())\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "models.append(QuadraticDiscriminantAnalysis())\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models.append(LogisticRegression())\n",
    "\n",
    "print('Models list imported. with length = {}'.format(len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XGBClassifier...\n",
      "Running RandomForestClassifier...\n",
      "Running AdaBoostClassifier...\n",
      "Running GradientBoostingClassifier...\n",
      "Running DecisionTreeClassifier...\n",
      "Running KNeighborsClassifier...\n",
      "Running SVC...\n",
      "Running GaussianNB...\n",
      "Running LinearDiscriminantAnalysis...\n",
      "Running QuadraticDiscriminantAnalysis...\n",
      "Running LogisticRegression...\n",
      "     acc_dev  acc_train                           name\n",
      "0   0.833333   0.928839                  XGBClassifier\n",
      "1   0.811111   0.981273         RandomForestClassifier\n",
      "2   0.788889   0.850187             AdaBoostClassifier\n",
      "3   0.822222   0.911361     GradientBoostingClassifier\n",
      "4   0.777778   0.988764         DecisionTreeClassifier\n",
      "5   0.788889   0.865169           KNeighborsClassifier\n",
      "6   0.755556   0.841448                            SVC\n",
      "7   0.766667   0.806492                     GaussianNB\n",
      "8   0.766667   0.843945     LinearDiscriminantAnalysis\n",
      "9   0.677778   0.685393  QuadraticDiscriminantAnalysis\n",
      "10  0.766667   0.841448             LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "df_acc = pd.DataFrame()\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    print('Running {}...'.format(model_name))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, y_train_pred)\n",
    "    y_dev_pred = model.predict(X_dev)\n",
    "    acc_dev = accuracy_score(y_dev, y_dev_pred)\n",
    "    \n",
    "    df_acc = df_acc.append({'name': model_name, 'acc_dev': acc_dev, 'acc_train': acc_train}, ignore_index=True)\n",
    "        \n",
    "print(df_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    from xgboost import XGBClassifier\n",
    "    \n",
    "#     param = {'objective':'binary:logistic', 'n_estimators': 20, 'n_jobs': 4\n",
    "#              , 'max_depth': 50, 'learning_rate': 0.3, 'reg_lambda': 0.01\n",
    "#              , 'gamma': 2, 'max_delta_step': 1, 'min_child_weight': 1\n",
    "#              , 'colsample_bytree': 0.65, 'subsample': 0.9, 'base_score': 0.5\n",
    "#             }\n",
    "#     model = XGBClassifier(**param)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    param = {'n_estimators': 180, 'min_samples_split': 3\n",
    "    #          , 'min_samples_leaf': 4, 'max_depth': 32, 'bootstrap': True\n",
    "             , 'max_features': 0.5\n",
    "            }  \n",
    "    model = RandomForestClassifier(**param)\n",
    "    \n",
    "#     from sklearn.tree import DecisionTreeClassifier\n",
    "#     model = DecisionTreeClassifier()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = getModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the best parameter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# grid = {'n_estimators':[20]\n",
    "#         , 'max_depth':[50]\n",
    "#         , 'learning_rate':[0.3]\n",
    "#         , 'reg_lambda':[0.01]\n",
    "#         , 'gamma':[2]\n",
    "#         , 'max_delta_step':[0,1,2]\n",
    "#         , 'min_child_weight':[1,2,3]\n",
    "#         , 'colsample_bytree':[0.55,0.65]\n",
    "#         , 'subsample':[1,0.9,0.8]\n",
    "#         , 'base_score':[0.5]        \n",
    "#        }\n",
    "\n",
    "# search = GridSearchCV(estimator=model, param_grid=grid, scoring='accuracy', n_jobs=4, refit=True)\n",
    "# search.fit(X_train, y_train)\n",
    "\n",
    "# print(search.best_params_)\n",
    "# print(search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=0.5, min_samples_split=3, n_estimators=180)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train\n",
    "#           , eval_set=[(X_train, y_train), (X_dev, y_dev)]\n",
    "#           , eval_metric=['error', 'logloss'], verbose=True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train data: 0.9850187265917603\n",
      "Accuracy of train data: 0.8222222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "print('Accuracy of train data:', accuracy_score(y_train, y_train_pred))\n",
    "y_dev_pred = model.predict(X_dev)\n",
    "print('Accuracy of train data:', accuracy_score(y_dev, y_dev_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_raw = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "df_submit = preprocessor_0(df_submit_raw)\n",
    "X_submit = preprocessor_1.transform(df_submit)\n",
    "\n",
    "df_submit_final = pd.DataFrame(df_submit_raw['PassengerId'])\n",
    "df_submit_final['Survived'] = pd.Series(model.predict(X_submit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit_final.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
